{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1-final"},"colab":{"name":"hw_backprop.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mo4MwTZtocWC","colab_type":"text"},"source":["# Backprop своими руками"]},{"cell_type":"markdown","metadata":{"id":"ZTn-EUeLocWG","colab_type":"text"},"source":["Материалы:\n","\n","* [Andrew Karpahy: yes, you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)\n","* [Stanford CS231n](http://cs231n.stanford.edu/)\n","* [Deep Learning](http://sereja.me/f/deep_learning_goodfellow.pdf) — с 204 страницы и до прозрения\n","* [Xavier, Bengio](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)"]},{"cell_type":"markdown","metadata":{"id":"vr9onIFLocWI","colab_type":"text"},"source":["<img width='800px' src='https://cdn-images-1.medium.com/max/1600/1*q1M7LGiDTirwU-4LcFq7_Q.png'>"]},{"cell_type":"markdown","metadata":{"id":"0pNAiOscocWJ","colab_type":"text"},"source":["Иногда сети пишут на чистом C++, причём код для обучения и инференса (реального прогона в продакшне) — отдельно. Так делают, когда нужен очень быстрый отклик и высокая производительность, но это очень трудоемко.\n","\n","Большинство людей не усложняют себе жизнь и просто используют фреймворки — с ними можно просто почти декларативно описать, какие операции хотите сделать с данными, а он потом сам построит сеть и подгонит её под данные.\n","\n","Ваше задание — реализовать свой небольшой фреймворк глубокого обучения на чистом `numpy`. Основное время у вас должно уйти на вывод формул для градиентов, анализ поведения самых часто используемых слоев в современных нейросетях и прочий матан. Хотя бы один раз в жизни это надо сделать, а уже потом пользоваться готовыми абстракциями."]},{"cell_type":"markdown","metadata":{"id":"boLW-DeTocWL","colab_type":"text"},"source":["Предполагаемый порядок выполнения:\n","* Поймите на высоком уровне, как работает алгоритм backpropagation\n","* Изучите пример с логиситической регрессией, чтобы понять, что от вас в итоге хотят\n","* Изучите код `Module`\n","* `Sequential`\n","* `Linear`\n","* `SoftMax`\n","* `CrossEntropy`\n","* Протестируйте их на логситической регрессии\n","* Напишите код для решения MNIST\n","* Дописывайте остальные слои, пока не получите на нём 97%"]},{"cell_type":"markdown","metadata":{"id":"sPciq6WzocWN","colab_type":"text"},"source":["Оценивание (суммарно до 20 баллов):\n","* 5 баллов -- что-то хоть как-то обучается, MNIST на валидации >90%\n","* 2 балла -- MNIST на 95%, дальше по одному баллу за 96%, 97% и 98%. Это будет сделать намного сложнее, чем через PyTorch, потому что вам всё нужно писать самим: более сложные оптимизаторы, learning rate decay, думать про численную стабильность и т. д.\n","* По 2 балла за слои: LeakyReLU, Dropout, BatchNorm, CrossEntropy, SoftMax"]},{"cell_type":"markdown","metadata":{"id":"VrI9amBAocWO","colab_type":"text"},"source":["Советы:\n","* Чтобы лучше понять, что должно в итоге получиться, изучите «игрушечный пример» и вообще эту тетрадку, а потом начните читать `hw_framework.py`, где будет более техничное описание.\n","* Для дебага проверяйте градиенты численно — сдвигайте параметры на какой-нибудь эпсилон и смотрите разницу. Ещё можете проверить, что на одинаковых данных они дают то же, что их эквиваленты из PyTorch (можно после каждого нового слоя добавить юнит тест через `assert`).\n","* Пишите код без циклов — в питоне они очень долгие; все вычисления можно делать внутри numpy.\n","* Ограничение на срок сдачи большое — до конца всего курса, но рекомендуется закончить примерно за месяц. Дописывайте его постепенно, разбираясь, как работает каждая функция активации.\n","* Обсуждайте математику и общую архитектуру фреймворка, но не шарьте друг другу код — так не интересно."]},{"cell_type":"code","metadata":{"id":"osDsI56TocWQ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rArLbzznocWU","colab_type":"text"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"9SpmBG6XocWV","colab_type":"text"},"source":["Откройте в Jupyter две тетрадки — эту и `hw_framework.ipynb`. В этой содержится train loop, а там непосредственно ваш «фреймворк», который вам ещё предстоит написать.\n","\n","Архитектура фреймворка вдохновлена PyTorch. Как всегда, если придумаете какой-то более клёвый дизайн — можете использовать его."]},{"cell_type":"code","metadata":{"id":"AR35O38uocWX","colab_type":"code","colab":{}},"source":["%run hw_framework.ipynb"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 373 ms, sys: 15.2 ms, total: 388 ms\n","Wall time: 73 ms\n","CPU times: user 45.6 ms, sys: 4.69 ms, total: 50.3 ms\n","Wall time: 8.38 ms\n","/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/IPython/core/magic.py:187: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  call = lambda f, *a, **k: f(*a, **k)\n"]}]},{"cell_type":"markdown","metadata":{"id":"Z03GIF03ocWc","colab_type":"text"},"source":["Мы будем использовать самый простой вариант градиентного спуска: просто пройдемся по всем параметрам и сделаем шаги в сторону уменьшения посчитанного заранее градиента.\n","\n","Есть [более продвинутые методы](http://ruder.io/optimizing-gradient-descent/), но пока что мы их использовать не будем."]},{"cell_type":"code","metadata":{"id":"gIkgsfAXocWd","colab_type":"code","colab":{}},"source":["def SGD(params, gradients, lr=1e-3):    \n","    for weights, gradient in zip(params, gradients):\n","        #print(type(lr), type(gradient))\n","        #print(lr, gradient)\n","        weights -= lr * gradient"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PfBYatsKocWh","colab_type":"text"},"source":["Cоздадим обертку вокруг нашего датасета (просто numpy-евские массивы), которую будем потом использовать, чтобы итерироваться по нему."]},{"cell_type":"code","metadata":{"id":"jDmJKg8hocWi","colab_type":"code","colab":{}},"source":["def loader(X, Y, batch_size):    \n","    n = X.shape[0]\n","\n","    # в начале каждой эпохи будем всё перемешивать\n","    # важно, что мы пермешиваем индексы, а не X\n","    indices = np.arange(n)\n","    np.random.shuffle(indices)\n","    \n","    for start in range(0, n, batch_size):\n","        # в конце нам, возможно, нужно взять неполный батч\n","        end = min(start + batch_size, n)\n","        \n","        batch_idx = indices[start:end]\n","    \n","        yield X[batch_idx], Y[batch_idx]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yMcWZrUPocWm","colab_type":"text"},"source":["В следующих двух секциях — игрушечные примеры регрессии и классификации на синтезированных данных. В них ничего менять не надо — они нужны, чтобы отдебажить ваши слои в `hw_framework`."]},{"cell_type":"markdown","metadata":{"id":"MLPP2pyMocWn","colab_type":"text"},"source":["# Линейная регрессия"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"i2oHX9NQocWo","colab_type":"code","colab":{}},"source":["n = 1000\n","batch_size = 10\n","\n","X = np.random.randn(batch_size, n)\n","display(X.shape)\n","#display(X.shape)\n","true_w = np.random.randn(n, 1)\n","#display(true_w)\n","Y = np.dot(X, true_w).reshape(n) + np.random.randn()/5\n","\n","#display(Y)\n","\n","print('best_possible_mse:', np.mean(np.power(Y-np.dot(X, true_w).reshape(n), 2)))\n","Y = Y.reshape(batch_size, 1)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"(10, 1000)"},"metadata":{}},{"output_type":"error","ename":"ValueError","evalue":"cannot reshape array of size 10 into shape (1000,)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-159c085fdc5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrue_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#display(true_w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#display(Y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10 into shape (1000,)"]}]},{"cell_type":"markdown","metadata":{"id":"gu4bulrKocWs","colab_type":"text"},"source":["### Модель"]},{"cell_type":"code","metadata":{"id":"2bHZzM0XocWt","colab_type":"code","colab":{}},"source":[],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dsdkT55BocWx","colab_type":"text"},"source":["\n","Можете тут потом тестировать остальные свои слои, когда их напишите."]},{"cell_type":"markdown","metadata":{"id":"G6cJy-nOocWy","colab_type":"text"},"source":["### Обучение"]},{"cell_type":"code","metadata":{"id":"P3Y7VImUocW0","colab_type":"code","colab":{}},"source":["\n","model = Sequential(\n","    Linear(n, 1),\n",")\n","\n","criterion = MSE()\n","epochs = 100\n","learning_rate = 1e-3\n","bach_size = 10\n","samples = 50\n","X = np.random.randn(samples, n)\n","true_w = np.random.randn(n, 1)\n","#display(true_w)\n","Y = np.dot(X, true_w)\n","#Y = Y.reshape(samples)\n","display(X.shape)\n","display(Y.shape)"],"execution_count":90,"outputs":[{"output_type":"display_data","data":{"text/plain":"(50, 1000)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(50, 1)"},"metadata":{}}]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 321 ms, sys: 10.9 ms, total: 332 ms\nWall time: 55.8 ms\nCPU times: user 31.2 ms, sys: 328 µs, total: 31.5 ms\nWall time: 5.16 ms\n"]},{"output_type":"display_data","data":{"text/plain":"(1, 2)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(1, 1)"},"metadata":{}}],"source":["%run hw_framework.ipynb\n","\n","model = Sequential(\n","    Linear(2, 1),\n",")\n","criterion = MSE()\n","epochs = 30\n","learning_rate = 1e-3\n","batch_size = 1\n","X = np.array([[5, 4]])\n","Y = np.array([[21]])\n","display(X.shape)\n","display(Y.shape)\n"]},{"cell_type":"code","metadata":{"id":"8NHCVPRiocW4","colab_type":"code","colab":{},"tags":[]},"source":["import framework as fw\n","\n","history = []\n","\n","model = fw.Sequential(\n","    Linear(2, 1),\n",")\n","criterion = fw.MSE()\n","epochs = 100\n","learning_rate = 1e-3\n","batch_size = 1\n","X = np.array([[5, 4]])\n","Y = np.array([[21]])\n","print(X.shape)\n","print(Y.shape)\n","\n","\n","\n","\n","for i in range(epochs):\n","    for x, y_true in fw.loader(X, Y, batch_size):\n","        # forward -- считаем все значения до функции потерь\n","        #print(f'x : {x} x.shape = {x.shape}')\n","        #display(y_true.reshape(batch_size).shape)\n","        y_pred = model.forward(x)\n","        #print(f'y_true = {y_true} y_true.shape = {y_true.shape}')\n","        #print(f'y_pred = {y_pred} y_pred.shape = {y_pred.shape}')\n","        #print(f'model.W = {model.layers[0].W}')\n","\n","\n","        #display(y_pred)\n","        #display(y_true)\n","        #display(y_pred - y_true)\n","        loss = criterion.forward(y_pred, y_true)\n","        #print(f'loss: {loss}')\n","\n","        #print(y_pred, y_true)\n","        #print('SUM OF SQUARES:', np.mean(np.power(y_pred-y_true, 2)))\n","    \n","        # backward -- считаем все градиенты в обратном порядке\n","        grad = criterion.backward(y_pred, y_true)\n","        #print(f'grad = {grad} grad.shape = {grad.shape}')\n","        #display((y_pred - y_true))\n","        #print(f'input gradient = {model.backward(x, grad)}')\n","        \n","        # обновляем веса\n","        fw.SGD(model.parameters(),\n","            model.grad_parameters(),\n","            learning_rate)\n","        \n","        #print(model.layers[0].W[0][0])\n","        #print(loss)\n","        \n","        #print()\n","        #print('----------------------------------')\n","        #print()\n","\n","        \n","        history.append(loss)\n","        #display()\n","        #display('----------------------------------')\n","        #display()\n","\n","    \n","plt.title(\"Training loss\")\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"loss\")\n","plt.plot(history, 'b')\n","plt.show()"],"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 2)\n(1, 1)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'Linear' object has no attribute 'grad_W'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-1aa81c66476d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# обновляем веса\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         fw.SGD(model.parameters(),\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             learning_rate)\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/Google Drive/DL/Lesson3/framework.py\u001b[0m in \u001b[0;36mgrad_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-97-4bc93428e923>\u001b[0m in \u001b[0;36mgrad_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgrad_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_W\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'Linear' object has no attribute 'grad_W'"]}]},{"cell_type":"markdown","metadata":{"id":"33YJP2KeocW8","colab_type":"text"},"source":["# Логистическая регрессия\n","\n","Этот пример нужнен для теситрования классификации (`CrossEntropy` и `SoftMax`).\n","\n","Возьмем в качестве датасета точки из двух гауссиан на плоскости."]},{"cell_type":"code","metadata":{"scrolled":false,"id":"Vy-6IgGWocW9","colab_type":"code","colab":{}},"source":["n = 500\n","\n","X1 = np.random.randn(n, 2) + np.array([2, 2])\n","X2 = np.random.randn(n, 2) + np.array([-2, -2])\n","X = np.vstack([X1, X2])\n","\n","Y = np.concatenate([np.ones(n), np.zeros(n)])[:, None]\n","Y = np.hstack([Y, 1-Y])\n","\n","plt.scatter(X[:,0], X[:,1], c=Y[:,0])\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g6ga19VxocXB","colab_type":"text"},"source":["Обратите внимание на `y`. Он в формате one-hot: у каждого вектора все нули, кроме одной единицы.\n","\n","Выходные данные в таком формате упростят написание `CrossEntropy`."]},{"cell_type":"markdown","metadata":{"id":"zNDguGQXocXD","colab_type":"text"},"source":["### Модель\n","\n","Логистическая регрессия — это тоже как бы маленькая нейронка: линейный слой, софтмакс, и максимизируем правдоподобие."]},{"cell_type":"code","metadata":{"id":"fdKlc0EgocXE","colab_type":"code","colab":{}},"source":["model = Sequential(\n","    Linear(2, 2),\n","    SoftMax()\n",")\n","\n","criterion = CrossEntropy()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NMoT8yXCocXI","colab_type":"text"},"source":["### Обучение"]},{"cell_type":"code","metadata":{"id":"KIk7RXUrocXJ","colab_type":"code","colab":{}},"source":["epochs = 10\n","batch_size = 16\n","learning_rate = 1e-2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"6RU473D9ocXN","colab_type":"code","colab":{}},"source":["history = []\n","\n","for i in range(epochs):\n","    for x, y_true in loader(X, Y, batch_size):\n","        # forward: считаем все значения до функции потерь\n","        y_pred = model.forward(x)\n","        loss = criterion.forward(y_pred, y_true)\n","    \n","        # backward: считаем все градиенты в обратном порядке\n","        grad = criterion.backward(y_pred, y_true)\n","        model.backward(x, grad)\n","        \n","        # обновляем веса\n","        SGD(model.parameters(),\n","            model.grad_parameters(),\n","            learning_rate)\n","        \n","        # логгируем лосс\n","        # history.append(loss)\n","\n","    \n","plt.title(\"Training loss\")\n","plt.xlabel(\"iteration\")\n","plt.ylabel(\"loss\")\n","plt.plot(history, 'b')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mc_7Av6uocXR","colab_type":"text"},"source":["Мы тут пропустили много важных деталей: валидация, подсчет точности (кроссэнтропия не очень информативна), регуляризация. Вам всё это нужно будет реализовать потом самим."]},{"cell_type":"markdown","metadata":{"id":"tmqQxNhFocXS","colab_type":"text"},"source":["# Теперь сами"]},{"cell_type":"code","metadata":{"id":"BRYIbyvzocXT","colab_type":"code","colab":{}},"source":["import os\n","from sklearn.datasets import fetch_mldata\n","# эти библиотеки нужны только для того, чтобы скачать MNISt\n","\n","if os.path.exists('mnist.npz'):\n","    with np.load('mnist.npz', 'r') as data:\n","        X = data['X']\n","        y = data['y']\n","else:\n","    mnist = fetch_mldata(\"mnist-original\")\n","    # очень важно его отнормировать -- см. Linear в hw_framework\n","    X = mnist.data / 255.0\n","    y = mnist.target\n","    np.savez('mnist.npz', X=X, y=y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FPZV7JdYocXa","colab_type":"text"},"source":["Переведите лейблы в one-hot."]},{"cell_type":"code","metadata":{"id":"A0n63WKSocXc","colab_type":"code","colab":{}},"source":["# ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d726biJBocXj","colab_type":"text"},"source":["Разделите датасет на train и validation."]},{"cell_type":"code","metadata":{"id":"VDMMhl24ocXk","colab_type":"code","colab":{}},"source":["# ..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XHv3CVCIocXo","colab_type":"text"},"source":["Теперь напишите модель и train loop. Можете начать с адаптации предыдущего примера.\n","\n","Дальше начинается творческая часть и настоящий Deep Learning:\n","* поиграйтесь с архитектурами;\n","* поиграйтесь с learning rate и batch_size;\n","* сделайте learning rate decay;\n","* сделайте data augmentation.\n","\n","Have fun. Дедлайн — не две недели, а до конца курса."]},{"cell_type":"code","metadata":{"id":"q4XW6uFEocXp","colab_type":"code","colab":{}},"source":["# ..."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHGcq3iMocXs","colab_type":"code","colab":{}},"source":["# ..."],"execution_count":0,"outputs":[]}]}